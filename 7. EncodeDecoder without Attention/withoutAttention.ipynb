{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "19e7570e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:05.567755Z",
          "iopub.status.busy": "2025-04-14T11:17:05.567531Z",
          "iopub.status.idle": "2025-04-14T11:17:11.368339Z",
          "shell.execute_reply": "2025-04-14T11:17:11.367739Z"
        },
        "papermill": {
          "duration": 5.805567,
          "end_time": "2025-04-14T11:17:11.369748",
          "exception": false,
          "start_time": "2025-04-14T11:17:05.564181",
          "status": "completed"
        },
        "tags": [],
        "id": "19e7570e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "0266704e",
      "metadata": {
        "id": "0266704e"
      },
      "outputs": [],
      "source": [
        "SEED = 123\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "35fc6cbc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.376785Z",
          "iopub.status.busy": "2025-04-14T11:17:11.376255Z",
          "iopub.status.idle": "2025-04-14T11:17:11.428413Z",
          "shell.execute_reply": "2025-04-14T11:17:11.427670Z"
        },
        "papermill": {
          "duration": 0.056622,
          "end_time": "2025-04-14T11:17:11.429516",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.372894",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35fc6cbc",
        "outputId": "f35b167e-39ef-493d-b458-081137481a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "6acd9c23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.436617Z",
          "iopub.status.busy": "2025-04-14T11:17:11.436040Z",
          "iopub.status.idle": "2025-04-14T11:17:11.439699Z",
          "shell.execute_reply": "2025-04-14T11:17:11.438982Z"
        },
        "papermill": {
          "duration": 0.00838,
          "end_time": "2025-04-14T11:17:11.440895",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.432515",
          "status": "completed"
        },
        "tags": [],
        "id": "6acd9c23"
      },
      "outputs": [],
      "source": [
        "def read_language_pairs(filepath, max_samples=10000):\n",
        "    \"\"\"Read language pairs from file with tab separation\"\"\"\n",
        "    pairs = []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if '\\t' in line:\n",
        "                parts = line.strip().split('\\t')\n",
        "                if len(parts) >= 2:\n",
        "                    source, target = parts[0], parts[1]\n",
        "                    pairs.append((source.lower(), target.lower()))\n",
        "\n",
        "    # Shuffle and limit sample size\n",
        "    random.shuffle(pairs)\n",
        "    return pairs[:max_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "356da8df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.447833Z",
          "iopub.status.busy": "2025-04-14T11:17:11.447263Z",
          "iopub.status.idle": "2025-04-14T11:17:11.451153Z",
          "shell.execute_reply": "2025-04-14T11:17:11.450621Z"
        },
        "papermill": {
          "duration": 0.008246,
          "end_time": "2025-04-14T11:17:11.452154",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.443908",
          "status": "completed"
        },
        "tags": [],
        "id": "356da8df"
      },
      "outputs": [],
      "source": [
        "def create_dictionary(sentences):\n",
        "    \"\"\"Create word-to-index dictionary from sentences\"\"\"\n",
        "    word_dict = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n",
        "\n",
        "    # Count all words\n",
        "    word_counts = Counter()\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        word_counts.update(words)\n",
        "\n",
        "    # Add words to dictionary\n",
        "    for word in word_counts:\n",
        "        if word not in word_dict:\n",
        "            word_dict[word] = len(word_dict)\n",
        "\n",
        "    return word_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "fc53644b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.458435Z",
          "iopub.status.busy": "2025-04-14T11:17:11.458203Z",
          "iopub.status.idle": "2025-04-14T11:17:11.462115Z",
          "shell.execute_reply": "2025-04-14T11:17:11.461441Z"
        },
        "papermill": {
          "duration": 0.008291,
          "end_time": "2025-04-14T11:17:11.463217",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.454926",
          "status": "completed"
        },
        "tags": [],
        "id": "fc53644b"
      },
      "outputs": [],
      "source": [
        "def words_to_indices(sentence, word_dict):\n",
        "    \"\"\"Convert words in a sentence to indices using dictionary\"\"\"\n",
        "    return [word_dict.get(word, word_dict['<unk>']) for word in sentence.split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "95007fc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.470079Z",
          "iopub.status.busy": "2025-04-14T11:17:11.469455Z",
          "iopub.status.idle": "2025-04-14T11:17:11.473099Z",
          "shell.execute_reply": "2025-04-14T11:17:11.472425Z"
        },
        "papermill": {
          "duration": 0.007976,
          "end_time": "2025-04-14T11:17:11.474107",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.466131",
          "status": "completed"
        },
        "tags": [],
        "id": "95007fc6"
      },
      "outputs": [],
      "source": [
        "def prepare_training_data(pairs, source_dict, target_dict):\n",
        "    \"\"\"Convert all sentence pairs to tensor format\"\"\"\n",
        "    source_tensors = []\n",
        "    target_tensors = []\n",
        "\n",
        "    for source_sent, target_sent in pairs:\n",
        "        # Convert source sentence\n",
        "        source_indices = words_to_indices(source_sent, source_dict)\n",
        "        source_tensor = torch.tensor(source_indices, dtype=torch.long)\n",
        "\n",
        "        # Convert target sentence with start/end tokens\n",
        "        target_indices = [target_dict['<start>']]\n",
        "        target_indices.extend(words_to_indices(target_sent, target_dict))\n",
        "        target_indices.append(target_dict['<end>'])\n",
        "        target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
        "\n",
        "        source_tensors.append(source_tensor)\n",
        "        target_tensors.append(target_tensor)\n",
        "\n",
        "    return source_tensors, target_tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "5116702d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.480644Z",
          "iopub.status.busy": "2025-04-14T11:17:11.480225Z",
          "iopub.status.idle": "2025-04-14T11:17:11.484271Z",
          "shell.execute_reply": "2025-04-14T11:17:11.483776Z"
        },
        "papermill": {
          "duration": 0.008268,
          "end_time": "2025-04-14T11:17:11.485179",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.476911",
          "status": "completed"
        },
        "tags": [],
        "id": "5116702d"
      },
      "outputs": [],
      "source": [
        "def create_batch(source_list, target_list, source_pad_idx, target_pad_idx, batch_size=64):\n",
        "    \"\"\"Create a batch of padded sequences\"\"\"\n",
        "    # Get batch indices\n",
        "    indices = list(range(len(source_list)))\n",
        "    random.shuffle(indices)\n",
        "    batch_indices = indices[:batch_size]\n",
        "\n",
        "    # Get sequences for this batch\n",
        "    source_batch = [source_list[i] for i in batch_indices]\n",
        "    target_batch = [target_list[i] for i in batch_indices]\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_sources = pad_sequence(source_batch, batch_first=True, padding_value=source_pad_idx)\n",
        "    padded_targets = pad_sequence(target_batch, batch_first=True, padding_value=target_pad_idx)\n",
        "\n",
        "    return padded_sources.to(device), padded_targets.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "e933b820",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.491708Z",
          "iopub.status.busy": "2025-04-14T11:17:11.491480Z",
          "iopub.status.idle": "2025-04-14T11:17:11.495154Z",
          "shell.execute_reply": "2025-04-14T11:17:11.494638Z"
        },
        "papermill": {
          "duration": 0.007949,
          "end_time": "2025-04-14T11:17:11.496130",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.488181",
          "status": "completed"
        },
        "tags": [],
        "id": "e933b820"
      },
      "outputs": [],
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, source):\n",
        "        # source shape: [batch_size, seq_len]\n",
        "        embedded = self.embedding(source)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Run through LSTM\n",
        "        _, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # Return final states\n",
        "        return hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "6049728e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.502497Z",
          "iopub.status.busy": "2025-04-14T11:17:11.502314Z",
          "iopub.status.idle": "2025-04-14T11:17:11.506603Z",
          "shell.execute_reply": "2025-04-14T11:17:11.505921Z"
        },
        "papermill": {
          "duration": 0.008711,
          "end_time": "2025-04-14T11:17:11.507761",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.499050",
          "status": "completed"
        },
        "tags": [],
        "id": "6049728e"
      },
      "outputs": [],
      "source": [
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.output_layer = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, target, hidden, cell):\n",
        "        # target shape: [batch_size]\n",
        "        embedded = self.embedding(target.unsqueeze(1))  # [batch_size, 1, embedding_dim]\n",
        "\n",
        "        # Run through LSTM\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "\n",
        "        # Project to vocabulary size\n",
        "        prediction = self.output_layer(output.squeeze(1))  # [batch_size, output_size]\n",
        "\n",
        "        return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "d7165203",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.514538Z",
          "iopub.status.busy": "2025-04-14T11:17:11.514162Z",
          "iopub.status.idle": "2025-04-14T11:17:11.519087Z",
          "shell.execute_reply": "2025-04-14T11:17:11.518420Z"
        },
        "papermill": {
          "duration": 0.009417,
          "end_time": "2025-04-14T11:17:11.520143",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.510726",
          "status": "completed"
        },
        "tags": [],
        "id": "d7165203"
      },
      "outputs": [],
      "source": [
        "class SimpleTranslator(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(SimpleTranslator, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        # source: [batch_size, source_len]\n",
        "        # target: [batch_size, target_len]\n",
        "\n",
        "        batch_size = target.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = self.decoder.output_layer.out_features\n",
        "\n",
        "        # Tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "\n",
        "        # Encode the source sequence\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "        # First input to the decoder is the <start> token\n",
        "        input = target[:, 0]\n",
        "\n",
        "        # Decode one step at a time\n",
        "        for t in range(1, target_len):\n",
        "            # Pass through decoder\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            # Store prediction\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            # Teacher forcing decision\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # Get next input (either from ground truth or prediction)\n",
        "            input = target[:, t] if teacher_force else output.argmax(1)\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "5ec815c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.526960Z",
          "iopub.status.busy": "2025-04-14T11:17:11.526768Z",
          "iopub.status.idle": "2025-04-14T11:17:11.531027Z",
          "shell.execute_reply": "2025-04-14T11:17:11.530317Z"
        },
        "papermill": {
          "duration": 0.008948,
          "end_time": "2025-04-14T11:17:11.532092",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.523144",
          "status": "completed"
        },
        "tags": [],
        "id": "5ec815c9"
      },
      "outputs": [],
      "source": [
        "def train_translator(model, train_source, train_target, val_source=None, val_target=None,\n",
        "                    epochs=5, batch_size=64, teacher_forcing=0.5):\n",
        "    \"\"\"Train the translator model\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=target_dict['<pad>'])\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Train on batches\n",
        "        for i in range(0, len(train_source), batch_size):\n",
        "            # Create batch\n",
        "            if i + batch_size <= len(train_source):\n",
        "                source_batch = train_source[i:i+batch_size]\n",
        "                target_batch = train_target[i:i+batch_size]\n",
        "\n",
        "                src, tgt = create_batch(source_batch, target_batch,\n",
        "                                       source_dict['<pad>'], target_dict['<pad>'],\n",
        "                                       batch_size=len(source_batch))\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(src, tgt, teacher_forcing_ratio=teacher_forcing)\n",
        "\n",
        "                # Calculate loss (ignoring padding and first token which is <start>)\n",
        "                output_flat = output[:, 1:].reshape(-1, output.shape[-1])\n",
        "                target_flat = tgt[:, 1:].reshape(-1)\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                # Prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                # Update weights\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "\n",
        "        # Validation\n",
        "        if val_source and val_target:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                # Sample validation data\n",
        "                val_indices = random.sample(range(len(val_source)), min(batch_size, len(val_source)))\n",
        "                val_src = [val_source[i] for i in val_indices]\n",
        "                val_tgt = [val_target[i] for i in val_indices]\n",
        "\n",
        "                src, tgt = create_batch(val_src, val_tgt,\n",
        "                                       source_dict['<pad>'], target_dict['<pad>'],\n",
        "                                       batch_size=len(val_src))\n",
        "\n",
        "                output = model(src, tgt, teacher_forcing_ratio=0)\n",
        "                val_loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]),\n",
        "                                    tgt[:, 1:].reshape(-1))\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/batch_count:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/batch_count:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "80b1f125",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.538923Z",
          "iopub.status.busy": "2025-04-14T11:17:11.538731Z",
          "iopub.status.idle": "2025-04-14T11:17:11.544453Z",
          "shell.execute_reply": "2025-04-14T11:17:11.543961Z"
        },
        "papermill": {
          "duration": 0.010357,
          "end_time": "2025-04-14T11:17:11.545425",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.535068",
          "status": "completed"
        },
        "tags": [],
        "id": "80b1f125"
      },
      "outputs": [],
      "source": [
        "def translate_text(model, sentence, max_length=50):\n",
        "    \"\"\"Translate a sentence using the trained model\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the sentence\n",
        "    tokens = words_to_indices(sentence.lower(), source_dict)\n",
        "    token_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # Encode\n",
        "    hidden, cell = model.encoder(token_tensor)\n",
        "\n",
        "    # Start with <start> token\n",
        "    input_token = torch.tensor([target_dict['<start>']]).to(device)\n",
        "\n",
        "    translated_tokens = []\n",
        "\n",
        "    # Generate translation\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(input_token, hidden, cell)\n",
        "\n",
        "        # Get predicted token\n",
        "        predicted_token = output.argmax(1).item()\n",
        "\n",
        "        # Stop if end token\n",
        "        if predicted_token == target_dict['<end>']:\n",
        "            break\n",
        "\n",
        "        translated_tokens.append(predicted_token)\n",
        "\n",
        "        # Next input is predicted token\n",
        "        input_token = torch.tensor([predicted_token], device=device)\n",
        "\n",
        "    # Convert indices back to words\n",
        "    translated_words = [index_to_target.get(idx, '<unk>') for idx in translated_tokens]\n",
        "\n",
        "    return ' '.join(translated_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "439fcfc4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.552137Z",
          "iopub.status.busy": "2025-04-14T11:17:11.551931Z",
          "iopub.status.idle": "2025-04-14T11:17:11.556908Z",
          "shell.execute_reply": "2025-04-14T11:17:11.556347Z"
        },
        "papermill": {
          "duration": 0.009508,
          "end_time": "2025-04-14T11:17:11.558002",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.548494",
          "status": "completed"
        },
        "tags": [],
        "id": "439fcfc4"
      },
      "outputs": [],
      "source": [
        "def evaluate_bleu(model, test_source, test_target, num_examples=100):\n",
        "    \"\"\"Calculate BLEU score on test data\"\"\"\n",
        "    model.eval()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    # Limit number of examples\n",
        "    samples = min(num_examples, len(test_source))\n",
        "\n",
        "    for i in range(samples):\n",
        "        # Get source sentence\n",
        "        source_words = [index_to_source[idx.item()] for idx in test_source[i]]\n",
        "        source_sentence = ' '.join(source_words)\n",
        "\n",
        "        # Get reference translation (remove <start> and <end>)\n",
        "        reference = [index_to_target[idx.item()] for idx in test_target[i]]\n",
        "        if reference[0] == '<start>':\n",
        "            reference = reference[1:]\n",
        "        if '<end>' in reference:\n",
        "            reference = reference[:reference.index('<end>')]\n",
        "\n",
        "        # Get model translation\n",
        "        translation = translate_text(model, source_sentence).split()\n",
        "\n",
        "        references.append([reference])\n",
        "        hypotheses.append(translation)\n",
        "\n",
        "    # Calculate BLEU score with smoothing\n",
        "    smooth = SmoothingFunction().method1\n",
        "    bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smooth)\n",
        "\n",
        "    return bleu_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "afe68ec8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-14T11:17:11.564714Z",
          "iopub.status.busy": "2025-04-14T11:17:11.564472Z",
          "iopub.status.idle": "2025-04-14T11:17:11.570907Z",
          "shell.execute_reply": "2025-04-14T11:17:11.570194Z"
        },
        "papermill": {
          "duration": 0.010916,
          "end_time": "2025-04-14T11:17:11.572004",
          "exception": false,
          "start_time": "2025-04-14T11:17:11.561088",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afe68ec8",
        "outputId": "ea660d1b-bbd9-4041-e877-1590a8501a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/200, Loss: 6.5574, Val Loss: 6.2627\n",
            "Epoch 2/200, Loss: 5.8222, Val Loss: 6.1216\n",
            "Epoch 3/200, Loss: 5.4977, Val Loss: 6.4002\n",
            "Epoch 4/200, Loss: 5.1625, Val Loss: 5.9553\n",
            "Epoch 5/200, Loss: 4.8117, Val Loss: 6.0286\n",
            "Epoch 6/200, Loss: 4.5061, Val Loss: 6.1359\n",
            "Epoch 7/200, Loss: 4.1452, Val Loss: 6.0226\n",
            "Epoch 8/200, Loss: 3.8482, Val Loss: 5.7406\n",
            "Epoch 9/200, Loss: 3.5530, Val Loss: 5.7089\n",
            "Epoch 10/200, Loss: 3.2282, Val Loss: 6.0160\n",
            "Epoch 11/200, Loss: 2.9906, Val Loss: 6.4006\n",
            "Epoch 12/200, Loss: 2.6721, Val Loss: 6.4148\n",
            "Epoch 13/200, Loss: 2.4595, Val Loss: 6.1318\n",
            "Epoch 14/200, Loss: 2.1660, Val Loss: 6.7837\n",
            "Epoch 15/200, Loss: 1.8865, Val Loss: 6.3859\n",
            "Epoch 16/200, Loss: 1.6532, Val Loss: 6.1936\n",
            "Epoch 17/200, Loss: 1.4011, Val Loss: 6.8556\n",
            "Epoch 18/200, Loss: 1.1607, Val Loss: 6.7325\n",
            "Epoch 19/200, Loss: 1.0084, Val Loss: 6.7755\n",
            "Epoch 20/200, Loss: 0.8142, Val Loss: 6.6876\n",
            "Epoch 21/200, Loss: 0.6848, Val Loss: 6.8457\n",
            "Epoch 22/200, Loss: 0.5632, Val Loss: 6.6789\n",
            "Epoch 23/200, Loss: 0.4724, Val Loss: 6.4734\n",
            "Epoch 24/200, Loss: 0.3797, Val Loss: 6.9581\n",
            "Epoch 25/200, Loss: 0.3096, Val Loss: 7.7020\n",
            "Epoch 26/200, Loss: 0.2521, Val Loss: 6.9384\n",
            "Epoch 27/200, Loss: 0.1953, Val Loss: 6.5810\n",
            "Epoch 28/200, Loss: 0.1636, Val Loss: 7.1637\n",
            "Epoch 29/200, Loss: 0.1265, Val Loss: 7.2730\n",
            "Epoch 30/200, Loss: 0.1009, Val Loss: 7.3261\n",
            "Epoch 31/200, Loss: 0.0829, Val Loss: 8.0778\n",
            "Epoch 32/200, Loss: 0.0706, Val Loss: 7.4344\n",
            "Epoch 33/200, Loss: 0.0608, Val Loss: 8.0363\n",
            "Epoch 34/200, Loss: 0.0537, Val Loss: 7.5892\n",
            "Epoch 35/200, Loss: 0.0494, Val Loss: 8.0148\n",
            "Epoch 36/200, Loss: 0.0432, Val Loss: 8.0784\n",
            "Epoch 37/200, Loss: 0.0421, Val Loss: 7.8342\n",
            "Epoch 38/200, Loss: 0.0377, Val Loss: 7.4056\n",
            "Epoch 39/200, Loss: 0.0354, Val Loss: 8.1417\n",
            "Epoch 40/200, Loss: 0.0313, Val Loss: 8.2582\n",
            "Epoch 41/200, Loss: 0.0292, Val Loss: 8.2555\n",
            "Epoch 42/200, Loss: 0.0267, Val Loss: 8.1712\n",
            "Epoch 43/200, Loss: 0.0299, Val Loss: 8.4632\n",
            "Epoch 44/200, Loss: 0.0300, Val Loss: 8.5760\n",
            "Epoch 45/200, Loss: 0.0297, Val Loss: 8.6169\n",
            "Epoch 46/200, Loss: 0.0343, Val Loss: 8.2055\n",
            "Epoch 47/200, Loss: 0.0361, Val Loss: 8.2873\n",
            "Epoch 48/200, Loss: 0.0423, Val Loss: 8.4046\n",
            "Epoch 49/200, Loss: 0.0498, Val Loss: 8.0039\n",
            "Epoch 50/200, Loss: 0.0537, Val Loss: 8.2414\n",
            "Epoch 51/200, Loss: 0.0381, Val Loss: 8.2224\n",
            "Epoch 52/200, Loss: 0.0319, Val Loss: 8.8151\n",
            "Epoch 53/200, Loss: 0.0288, Val Loss: 8.0555\n",
            "Epoch 54/200, Loss: 0.0275, Val Loss: 8.4933\n",
            "Epoch 55/200, Loss: 0.0255, Val Loss: 8.1993\n",
            "Epoch 56/200, Loss: 0.0215, Val Loss: 8.3141\n",
            "Epoch 57/200, Loss: 0.0200, Val Loss: 8.4664\n",
            "Epoch 58/200, Loss: 0.0175, Val Loss: 8.4748\n",
            "Epoch 59/200, Loss: 0.0172, Val Loss: 8.8732\n",
            "Epoch 60/200, Loss: 0.0158, Val Loss: 8.4369\n",
            "Epoch 61/200, Loss: 0.0121, Val Loss: 8.7233\n",
            "Epoch 62/200, Loss: 0.0091, Val Loss: 8.1219\n",
            "Epoch 63/200, Loss: 0.0070, Val Loss: 8.9633\n",
            "Epoch 64/200, Loss: 0.0068, Val Loss: 8.9461\n",
            "Epoch 65/200, Loss: 0.0056, Val Loss: 8.1224\n",
            "Epoch 66/200, Loss: 0.0054, Val Loss: 8.5890\n",
            "Epoch 67/200, Loss: 0.0059, Val Loss: 8.6785\n",
            "Epoch 68/200, Loss: 0.0054, Val Loss: 8.4642\n",
            "Epoch 69/200, Loss: 0.0062, Val Loss: 8.5628\n",
            "Epoch 70/200, Loss: 0.0062, Val Loss: 8.5010\n",
            "Epoch 71/200, Loss: 0.0067, Val Loss: 8.8974\n",
            "Epoch 72/200, Loss: 0.0074, Val Loss: 7.6232\n",
            "Epoch 73/200, Loss: 0.0083, Val Loss: 8.8068\n",
            "Epoch 74/200, Loss: 0.1648, Val Loss: 8.2516\n",
            "Epoch 75/200, Loss: 0.4346, Val Loss: 8.4164\n",
            "Epoch 76/200, Loss: 0.1740, Val Loss: 8.1334\n",
            "Epoch 77/200, Loss: 0.0562, Val Loss: 8.0432\n",
            "Epoch 78/200, Loss: 0.0213, Val Loss: 8.8355\n",
            "Epoch 79/200, Loss: 0.0109, Val Loss: 8.6803\n",
            "Epoch 80/200, Loss: 0.0075, Val Loss: 9.4787\n",
            "Epoch 81/200, Loss: 0.0067, Val Loss: 9.1338\n",
            "Epoch 82/200, Loss: 0.0057, Val Loss: 8.7130\n",
            "Epoch 83/200, Loss: 0.0055, Val Loss: 7.8715\n",
            "Epoch 84/200, Loss: 0.0048, Val Loss: 9.1433\n",
            "Epoch 85/200, Loss: 0.0046, Val Loss: 9.0776\n",
            "Epoch 86/200, Loss: 0.0043, Val Loss: 9.5414\n",
            "Epoch 87/200, Loss: 0.0044, Val Loss: 9.1982\n",
            "Epoch 88/200, Loss: 0.0055, Val Loss: 9.4706\n",
            "Epoch 89/200, Loss: 0.0079, Val Loss: 8.6756\n",
            "Epoch 90/200, Loss: 0.0050, Val Loss: 9.0524\n",
            "Epoch 91/200, Loss: 0.0056, Val Loss: 8.7353\n",
            "Epoch 92/200, Loss: 0.0052, Val Loss: 9.1260\n",
            "Epoch 93/200, Loss: 0.0042, Val Loss: 8.6759\n",
            "Epoch 94/200, Loss: 0.0060, Val Loss: 8.7821\n",
            "Epoch 95/200, Loss: 0.0070, Val Loss: 8.6711\n",
            "Epoch 96/200, Loss: 0.0052, Val Loss: 9.5888\n",
            "Epoch 97/200, Loss: 0.0039, Val Loss: 9.7989\n",
            "Epoch 98/200, Loss: 0.0053, Val Loss: 9.0956\n",
            "Epoch 99/200, Loss: 0.0044, Val Loss: 8.9561\n",
            "Epoch 100/200, Loss: 0.0032, Val Loss: 8.9581\n",
            "Epoch 101/200, Loss: 0.0038, Val Loss: 9.3845\n",
            "Epoch 102/200, Loss: 0.0042, Val Loss: 9.5412\n",
            "Epoch 103/200, Loss: 0.0034, Val Loss: 9.2630\n",
            "Epoch 104/200, Loss: 0.0040, Val Loss: 9.3201\n",
            "Epoch 105/200, Loss: 0.0055, Val Loss: 8.4066\n",
            "Epoch 106/200, Loss: 0.0045, Val Loss: 9.2112\n",
            "Epoch 107/200, Loss: 0.0032, Val Loss: 9.1663\n",
            "Epoch 108/200, Loss: 0.0030, Val Loss: 10.0117\n",
            "Epoch 109/200, Loss: 0.0047, Val Loss: 7.9658\n",
            "Epoch 110/200, Loss: 0.0042, Val Loss: 10.2783\n",
            "Epoch 111/200, Loss: 0.0052, Val Loss: 9.2751\n",
            "Epoch 112/200, Loss: 0.0061, Val Loss: 9.5071\n",
            "Epoch 113/200, Loss: 0.0533, Val Loss: 9.5821\n",
            "Epoch 114/200, Loss: 0.3862, Val Loss: 8.5768\n",
            "Epoch 115/200, Loss: 0.2020, Val Loss: 8.7764\n",
            "Epoch 116/200, Loss: 0.0567, Val Loss: 8.6332\n",
            "Epoch 117/200, Loss: 0.0153, Val Loss: 8.6195\n",
            "Epoch 118/200, Loss: 0.0071, Val Loss: 9.3360\n",
            "Epoch 119/200, Loss: 0.0070, Val Loss: 8.5087\n",
            "Epoch 120/200, Loss: 0.0055, Val Loss: 9.1538\n",
            "Epoch 121/200, Loss: 0.0051, Val Loss: 9.1904\n",
            "Epoch 122/200, Loss: 0.0046, Val Loss: 8.6024\n",
            "Epoch 123/200, Loss: 0.0040, Val Loss: 9.0321\n",
            "Epoch 124/200, Loss: 0.0041, Val Loss: 8.8554\n",
            "Epoch 125/200, Loss: 0.0041, Val Loss: 9.5573\n",
            "Epoch 126/200, Loss: 0.0038, Val Loss: 10.0037\n",
            "Epoch 127/200, Loss: 0.0047, Val Loss: 9.6878\n",
            "Epoch 128/200, Loss: 0.0033, Val Loss: 9.2046\n",
            "Epoch 129/200, Loss: 0.0032, Val Loss: 8.9818\n",
            "Epoch 130/200, Loss: 0.0030, Val Loss: 9.4065\n",
            "Epoch 131/200, Loss: 0.0049, Val Loss: 8.7851\n",
            "Epoch 132/200, Loss: 0.0037, Val Loss: 9.5544\n",
            "Epoch 133/200, Loss: 0.0044, Val Loss: 9.3918\n",
            "Epoch 134/200, Loss: 0.0039, Val Loss: 9.7150\n",
            "Epoch 135/200, Loss: 0.0043, Val Loss: 9.2391\n",
            "Epoch 136/200, Loss: 0.0032, Val Loss: 9.6843\n",
            "Epoch 137/200, Loss: 0.0040, Val Loss: 9.4339\n",
            "Epoch 138/200, Loss: 0.0047, Val Loss: 9.7936\n",
            "Epoch 139/200, Loss: 0.0041, Val Loss: 9.4101\n",
            "Epoch 140/200, Loss: 0.0040, Val Loss: 10.0202\n",
            "Epoch 141/200, Loss: 0.0044, Val Loss: 9.8226\n",
            "Epoch 142/200, Loss: 0.0037, Val Loss: 9.4589\n",
            "Epoch 143/200, Loss: 0.0040, Val Loss: 8.8769\n",
            "Epoch 144/200, Loss: 0.0038, Val Loss: 8.9402\n",
            "Epoch 145/200, Loss: 0.0034, Val Loss: 9.2385\n",
            "Epoch 146/200, Loss: 0.0034, Val Loss: 10.1206\n",
            "Epoch 147/200, Loss: 0.0033, Val Loss: 9.9989\n",
            "Epoch 148/200, Loss: 0.0042, Val Loss: 9.4744\n",
            "Epoch 149/200, Loss: 0.0031, Val Loss: 9.2463\n",
            "Epoch 150/200, Loss: 0.0027, Val Loss: 10.1529\n",
            "Epoch 151/200, Loss: 0.0023, Val Loss: 9.7087\n",
            "Epoch 152/200, Loss: 0.0023, Val Loss: 9.2406\n",
            "Epoch 153/200, Loss: 0.0025, Val Loss: 10.0005\n",
            "Epoch 154/200, Loss: 0.0030, Val Loss: 10.0374\n",
            "Epoch 155/200, Loss: 0.0032, Val Loss: 9.8800\n",
            "Epoch 156/200, Loss: 0.0023, Val Loss: 9.6813\n",
            "Epoch 157/200, Loss: 0.0032, Val Loss: 9.7412\n",
            "Epoch 158/200, Loss: 0.0037, Val Loss: 9.2996\n",
            "Epoch 159/200, Loss: 0.0039, Val Loss: 9.8575\n",
            "Epoch 160/200, Loss: 0.0032, Val Loss: 10.3502\n",
            "Epoch 161/200, Loss: 0.0035, Val Loss: 9.8498\n",
            "Epoch 162/200, Loss: 0.0037, Val Loss: 9.4713\n",
            "Epoch 163/200, Loss: 0.0033, Val Loss: 10.5526\n",
            "Epoch 164/200, Loss: 0.0114, Val Loss: 8.9202\n",
            "Epoch 165/200, Loss: 0.3197, Val Loss: 9.1887\n",
            "Epoch 166/200, Loss: 0.2565, Val Loss: 9.4835\n",
            "Epoch 167/200, Loss: 0.0769, Val Loss: 8.8745\n",
            "Epoch 168/200, Loss: 0.0254, Val Loss: 9.2695\n",
            "Epoch 169/200, Loss: 0.0106, Val Loss: 9.2586\n",
            "Epoch 170/200, Loss: 0.0079, Val Loss: 9.5262\n",
            "Epoch 171/200, Loss: 0.0047, Val Loss: 8.7622\n",
            "Epoch 172/200, Loss: 0.0040, Val Loss: 9.5191\n",
            "Epoch 173/200, Loss: 0.0036, Val Loss: 9.6687\n",
            "Epoch 174/200, Loss: 0.0033, Val Loss: 8.8924\n",
            "Epoch 175/200, Loss: 0.0038, Val Loss: 9.8463\n",
            "Epoch 176/200, Loss: 0.0034, Val Loss: 9.4377\n",
            "Epoch 177/200, Loss: 0.0031, Val Loss: 9.7417\n",
            "Epoch 178/200, Loss: 0.0033, Val Loss: 9.7293\n",
            "Epoch 179/200, Loss: 0.0029, Val Loss: 9.0089\n",
            "Epoch 180/200, Loss: 0.0030, Val Loss: 9.2550\n",
            "Epoch 181/200, Loss: 0.0024, Val Loss: 9.5521\n",
            "Epoch 182/200, Loss: 0.0029, Val Loss: 8.8480\n",
            "Epoch 183/200, Loss: 0.0028, Val Loss: 9.6677\n",
            "Epoch 184/200, Loss: 0.0031, Val Loss: 8.7767\n",
            "Epoch 185/200, Loss: 0.0024, Val Loss: 8.7425\n",
            "Epoch 186/200, Loss: 0.0031, Val Loss: 9.8253\n",
            "Epoch 187/200, Loss: 0.0023, Val Loss: 9.5379\n",
            "Epoch 188/200, Loss: 0.0030, Val Loss: 9.9976\n",
            "Epoch 189/200, Loss: 0.0028, Val Loss: 9.7676\n",
            "Epoch 190/200, Loss: 0.0025, Val Loss: 9.6466\n",
            "Epoch 191/200, Loss: 0.0029, Val Loss: 10.1501\n",
            "Epoch 192/200, Loss: 0.0028, Val Loss: 9.3751\n",
            "Epoch 193/200, Loss: 0.0047, Val Loss: 10.2613\n",
            "Epoch 194/200, Loss: 0.0031, Val Loss: 9.9772\n",
            "Epoch 195/200, Loss: 0.0038, Val Loss: 9.8511\n",
            "Epoch 196/200, Loss: 0.0029, Val Loss: 10.8875\n",
            "Epoch 197/200, Loss: 0.0023, Val Loss: 9.8436\n",
            "Epoch 198/200, Loss: 0.0031, Val Loss: 10.3373\n",
            "Epoch 199/200, Loss: 0.0022, Val Loss: 9.4202\n",
            "Epoch 200/200, Loss: 0.0023, Val Loss: 10.8427\n",
            "\n",
            "Translation examples:\n",
            "English: I am happy.\n",
            "Spanish: estoy ocupada.\n",
            "\n",
            "English: How are you?\n",
            "Spanish: los zapatos aquí?\n",
            "\n",
            "English: Where is the restaurant?\n",
            "Spanish: ¿dónde está la panadería\n",
            "\n",
            "English: Thank you very much.\n",
            "Spanish: muchas gracias\n",
            "\n",
            "BLEU Score: 0.0878\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/dataset.txt\"\n",
        "language_pairs = read_language_pairs(data_path, max_samples=10000)\n",
        "\n",
        "# Split source and target languages\n",
        "source_sentences = [pair[0] for pair in language_pairs]\n",
        "target_sentences = [pair[1] for pair in language_pairs]\n",
        "\n",
        "# Create dictionaries\n",
        "source_dict = create_dictionary(source_sentences)\n",
        "target_dict = create_dictionary(target_sentences)\n",
        "\n",
        "# Create reverse mappings\n",
        "index_to_source = {idx: word for word, idx in source_dict.items()}\n",
        "index_to_target = {idx: word for word, idx in target_dict.items()}\n",
        "\n",
        "# Prepare data\n",
        "source_data, target_data = prepare_training_data(language_pairs, source_dict, target_dict)\n",
        "\n",
        "# Split data\n",
        "source_train, source_test, target_train, target_test = train_test_split(\n",
        "    source_data, target_data, test_size=0.1, random_state=SEED)\n",
        "\n",
        "source_train, source_val, target_train, target_val = train_test_split(\n",
        "    source_train, target_train, test_size=0.1, random_state=SEED)\n",
        "\n",
        "# Create model\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "\n",
        "# Initialize model components\n",
        "encoder = LSTMEncoder(len(source_dict), EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "decoder = LSTMDecoder(len(target_dict), EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "model = SimpleTranslator(encoder, decoder).to(device)\n",
        "\n",
        "# Train the model\n",
        "train_translator(\n",
        "    model,\n",
        "    source_train, target_train,\n",
        "    val_source=source_val, val_target=target_val,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    teacher_forcing=0.5\n",
        ")\n",
        "\n",
        "# Test translation examples\n",
        "test_sentences = [\n",
        "    \"I am happy.\",\n",
        "    \"How are you?\",\n",
        "    \"Where is the restaurant?\",\n",
        "    \"Thank you very much.\"\n",
        "]\n",
        "\n",
        "print(\"\\nTranslation examples:\")\n",
        "for sentence in test_sentences:\n",
        "    translation = translate_text(model, sentence)\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Spanish: {translation}\")\n",
        "    print()\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu = evaluate_bleu(model, source_test, target_test, num_examples=100)\n",
        "print(f\"BLEU Score: {bleu:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/dataset.txt\"\n",
        "language_pairs = read_language_pairs(data_path, max_samples=10000)\n",
        "\n",
        "# Split source and target languages\n",
        "source_sentences = [pair[0] for pair in language_pairs]\n",
        "target_sentences = [pair[1] for pair in language_pairs]\n",
        "\n",
        "# Create dictionaries\n",
        "source_dict = create_dictionary(source_sentences)\n",
        "target_dict = create_dictionary(target_sentences)\n",
        "\n",
        "# Create reverse mappings\n",
        "index_to_source = {idx: word for word, idx in source_dict.items()}\n",
        "index_to_target = {idx: word for word, idx in target_dict.items()}\n",
        "\n",
        "# Prepare data\n",
        "source_data, target_data = prepare_training_data(language_pairs, source_dict, target_dict)\n",
        "\n",
        "# Split data\n",
        "source_train, source_test, target_train, target_test = train_test_split(\n",
        "    source_data, target_data, test_size=0.1, random_state=SEED)\n",
        "\n",
        "source_train, source_val, target_train, target_val = train_test_split(\n",
        "    source_train, target_train, test_size=0.1, random_state=SEED)\n",
        "\n",
        "# Create model\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "\n",
        "# Initialize model components\n",
        "encoder = LSTMEncoder(len(source_dict), EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "decoder = LSTMDecoder(len(target_dict), EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "model = SimpleTranslator(encoder, decoder).to(device)\n",
        "\n",
        "# Train the model\n",
        "train_translator(\n",
        "    model,\n",
        "    source_train, target_train,\n",
        "    val_source=source_val, val_target=target_val,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    teacher_forcing=0.5\n",
        ")\n",
        "\n",
        "# Test translation examples\n",
        "test_sentences = [\n",
        "    \"I am happy.\",\n",
        "    \"How are you?\",\n",
        "    \"Where is the restaurant?\",\n",
        "    \"Thank you very much.\"\n",
        "]\n",
        "\n",
        "print(\"\\nTranslation examples:\")\n",
        "for sentence in test_sentences:\n",
        "    translation = translate_text(model, sentence)\n",
        "    print(f\"English: {sentence}\")\n",
        "    print(f\"Spanish: {translation}\")\n",
        "    print()\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu = evaluate_bleu(model, source_test, target_test, num_examples=100)\n",
        "print(f\"BLEU Score: {bleu:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNHkPaI-kySQ",
        "outputId": "332ec446-98e6-43bb-9ae7-c3702bf11dae"
      },
      "id": "HNHkPaI-kySQ",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/10, Loss: 6.5188, Val Loss: 6.2810\n",
            "Epoch 2/10, Loss: 5.7962, Val Loss: 6.2890\n",
            "Epoch 3/10, Loss: 5.4698, Val Loss: 6.3293\n",
            "Epoch 4/10, Loss: 5.1227, Val Loss: 6.2469\n",
            "Epoch 5/10, Loss: 4.7747, Val Loss: 5.8073\n",
            "Epoch 6/10, Loss: 4.4100, Val Loss: 5.8662\n",
            "Epoch 7/10, Loss: 4.0957, Val Loss: 6.2728\n",
            "Epoch 8/10, Loss: 3.7999, Val Loss: 6.1352\n",
            "Epoch 9/10, Loss: 3.4439, Val Loss: 6.2343\n",
            "Epoch 10/10, Loss: 3.1067, Val Loss: 5.8566\n",
            "\n",
            "Translation examples:\n",
            "English: I am happy.\n",
            "Spanish: estoy muy\n",
            "\n",
            "English: How are you?\n",
            "Spanish: ¿qué son\n",
            "\n",
            "English: Where is the restaurant?\n",
            "Spanish: ¿dónde está el padre?\n",
            "\n",
            "English: Thank you very much.\n",
            "Spanish: te\n",
            "\n",
            "BLEU Score: 0.0458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TsPOyUoLtrtI"
      },
      "id": "TsPOyUoLtrtI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7129342,
          "sourceId": 11385497,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31012,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6813.322625,
      "end_time": "2025-04-14T13:10:34.689159",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-14T11:17:01.366534",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}